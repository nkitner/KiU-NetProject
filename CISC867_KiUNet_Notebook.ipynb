{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CISC867_KiUNet_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "c1ed6d6705e859a7f012a2ac41d411a9addf463f1d7f40cb4f0181f989bc4467"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGupVVHzPJZ3",
        "outputId": "118a4d62-15ac-45e1-962f-ca79380822a3"
      },
      "source": [
        "# need to add dataset to a folder in google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOodGqpzC07H"
      },
      "source": [
        "Add the RITE dataset to your google drive for easy access"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNZ4gAgCCu3-"
      },
      "source": [
        "# Installs and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsFDj4jXiP63",
        "outputId": "4048c1cc-3ca6-4fef-9d11-d0696108bce9"
      },
      "source": [
        "! pip install SimpleITK\n",
        "! pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 2.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avqiqXFzLqSB"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import os\n",
        "import datetime\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import SimpleITK as sitk\n",
        "import pickle\n",
        "from tensorflow import saved_model as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3-wBEipCo5G"
      },
      "source": [
        "# Important functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wdJRS7yLxYQ"
      },
      "source": [
        "def import_data_numpy(path):\n",
        "    \"\"\"\n",
        "    Imports png images and returns as a list of tensors to be used in training\n",
        "    :param path: path to directory where images are\n",
        "    :return: list of Tensors\n",
        "    \"\"\"\n",
        "    tensor_list = []\n",
        "    for file in sorted(os.listdir(path)):\n",
        "        if file.endswith(\".png\") or file.endswith(\".tif\"):\n",
        "            # Converts to RGB because the vessel images are black and white\n",
        "            png_img = Image.open(os.path.join(path, file))\n",
        "            np_arr = normalize(np.array(png_img.getdata()).reshape((128, 128,3)))\n",
        "            # tensor = tf.convert_to_tensor(np_arr)\n",
        "            # Encodes images as tensors and adds to the list\n",
        "            tensor_list.append(np_arr)\n",
        "        # Returns list of tensors to be used in model\n",
        "    # tensor_list = np.asarray(tensor_list)\n",
        "    return np.asarray(tensor_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4OIF4oRhV7p"
      },
      "source": [
        "def import_data_numpy_mask(path):\n",
        "    \"\"\"\n",
        "    Imports png images and returns as a list of tensors to be used in training\n",
        "    :param path: path to directory where images are\n",
        "    :return: list of Tensors\n",
        "    \"\"\"\n",
        "    tensor_list = []\n",
        "    for file in sorted(os.listdir(path)):\n",
        "        if file.endswith(\".png\") or file.endswith(\".tif\"):\n",
        "            # Converts to RGB because the vessel images are black and white\n",
        "            png_img = Image.open(os.path.join(path, file)).convert('L')\n",
        "            np_arr = normalize(np.array(png_img.getdata()).reshape((128, 128,1)))\n",
        "            # tensor = tf.convert_to_tensor(np_arr)\n",
        "            # Encodes images as tensors and adds to the list\n",
        "            tensor_list.append(np_arr)\n",
        "        # Returns list of tensors to be used in model\n",
        "    # tensor_list = np.asarray(tensor_list)\n",
        "    return np.asarray(tensor_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QM1-GX8cWx4"
      },
      "source": [
        "def normalize(input_image):\n",
        "  max = np.max(input_image)\n",
        "  input_image = tf.cast(input_image, tf.float32) / max\n",
        "  return input_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4JneY8RRaKS"
      },
      "source": [
        "from keras import backend as K    #import backend for custom metric\n",
        "\n",
        "def recall_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    precision = precision_metric(y_true, y_pred)\n",
        "    recall = recall_metric(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEtUmDg_Ny6D"
      },
      "source": [
        "def _encoder_block_unet(input, num_filters):\n",
        "    \"\"\"\n",
        "    Encoder logic for U-Net\n",
        "    :param input: KerasTensor\n",
        "    :param num_filters: Int - number of output filters in convolution\n",
        "    :return: KerasTensor\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = layers.MaxPool2D((2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def _encoder_block_kinet(input, num_filters):\n",
        "    \"\"\"\n",
        "    Encoder logic for Ki-Net\n",
        "    :param input: KerasTensor\n",
        "    :param num_filters: Int - number of output filters in convolution\n",
        "    :return: KerasTensor\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = layers.UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    p = layers.MaxPool2D((2, 2))(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def _decoder_block_unet(input, num_filters):\n",
        "    \"\"\"\n",
        "    Decoder logic for U-Net\n",
        "    :param input: KerasTensor\n",
        "    :param num_filters: Int - number of output filters in convolution\n",
        "    :return: KerasTensor\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = layers.UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def _decoder_block_kinet(input, num_filters):\n",
        "    \"\"\"\n",
        "    Decoder logic for Ki-net\n",
        "    :param input: KerasTensor\n",
        "    :param num_filters: Int - number of output filters in convolution\n",
        "    :return: KerasTensor\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = layers.MaxPool2D((2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    print(type(x))\n",
        "    return x\n",
        "\n",
        "\n",
        "def _crfb(x1, x2, num_filters, scale_factor):\n",
        "    \"\"\"\n",
        "    CRFB is the cross residual fusion block which fuses the outputs at the specified layers\n",
        "    from one model to the other, and returns the results as input for the next step.\n",
        "    :param x1: KerasTensor\n",
        "    :param x2: KerasTensor\n",
        "    :param num_filters: Int - number of output filters in convolution\n",
        "    :param scale_factor: Float - scale factor for resizing (upsampling/downsampling) of output\n",
        "    :return: KerasTensor\n",
        "    \"\"\"\n",
        "    new_w = int(x2.shape[1] * scale_factor)\n",
        "    new_h = int(x2.shape[2] * scale_factor)\n",
        "    out = layers.Conv2D(num_filters, 3, padding=\"same\")(x2)\n",
        "    out = layers.Activation(\"relu\")(out)\n",
        "    out = tf.image.resize(out, [new_h, new_w])\n",
        "    output = layers.Add()([x1, out])\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-7_4NREN89T"
      },
      "source": [
        "def kiunet(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Architecture of the KiU-Net model, which combines the Ki-Net and U-Net architecture\n",
        "    :param input_shape: Tuple of the shape of the input\n",
        "    :return: keras.Model\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # ENCODER BLOCK #\n",
        "\n",
        "    s1 = _encoder_block_unet(inputs, 16)  # U NET ENCODER\n",
        "    k1 = _encoder_block_kinet(inputs, 16)  # KINET ENCODER\n",
        "    \n",
        "    u1 = _crfb(s1, k1, 16, 0.25)  # CRFB U1 UNET\n",
        "    o1 = _crfb(k1, s1, 16, 4)  # CRFB O1 KINET\n",
        "    \n",
        "    s2 = _encoder_block_unet(u1, 32)  # UNET ENCODER\n",
        "    k2 = _encoder_block_kinet(o1, 32)  # KINET ENCODER\n",
        "    \n",
        "    u2 = _crfb(s2, k2, 32, 0.0625)  # CRFB U2 UNET\n",
        "    o2 = _crfb(k2, s2, 32, 16)  # CRFB O2 KINET\n",
        "    \n",
        "\n",
        "    s3 = _encoder_block_unet(u2, 64)  # UNET ENCODER\n",
        "    k3 = _encoder_block_kinet(o2, 64)  # KINET ENCODER\n",
        "    \n",
        "\n",
        "    u3 = _crfb(s3, k3, 64, 0.015625)  # CRFB U3 UNET\n",
        "    o3 = _crfb(k3, s2, 64, 32)  # CRFB O3 KINET\n",
        "    \n",
        "\n",
        "    # DECODER BLOCK #\n",
        "\n",
        "    d1_u = _decoder_block_unet(u3, 32)  # UNET DECODER\n",
        "    d1_k = _decoder_block_kinet(o3, 32)  # KINET DECODER\n",
        "    \n",
        "\n",
        "    d_u1 = _crfb(d1_u, d1_k, 32, 0.0625)  # CRFB D_U1 UNET\n",
        "    \n",
        "    d_o1 = _crfb(d1_k, d1_u, 32, 16)  # CRFB D_O1 KINET\n",
        "    \n",
        "\n",
        "    out = layers.Add()([d_u1, s2])  # CONCATENTATION D_U1 & S2 UNET\n",
        "    out1 = layers.Add()([d_o1, k2])  # CONCATENTATION D_O1 & K2 KINET\n",
        "    \n",
        "\n",
        "    d2_u = _decoder_block_unet(out, 16)  # UNET DECODER\n",
        "    d2_k = _decoder_block_kinet(out1, 16)  # KINET DECODER\n",
        "   \n",
        "\n",
        "    d_u2 = _crfb(d2_u, d2_k, 16, 0.25)  # CRFB D_U2 UNET\n",
        "    d_o2 = _crfb(d2_k, d2_u, 16, 4)  # CRFB D_O2 KINET\n",
        "    \n",
        "\n",
        "    out = layers.Add()([d_u2, s1])  # CONCATENATION D_U2 & S1 UNET\n",
        "    out1 = layers.Add()([d_o2, k1])  # CONCATENATION D_O2 & K2 KINET\n",
        "    \n",
        "\n",
        "    d3_u = _decoder_block_unet(out, 8)  # UNET DECODER\n",
        "    d3_k = _decoder_block_kinet(out1, 8)  # KINET DECODER\n",
        "    \n",
        "\n",
        "    out = layers.Add()([d3_u, d3_k])  # FINAL CONCATENATION OUTPUT FROM UNET AND KINET\n",
        "\n",
        "    out = layers.Conv2D(num_classes, 1, padding=\"valid\", activation=\"relu\")(out)  # FINAL CONVOLUTIONAL LAYER\n",
        "    kiunet_model = keras.Model(inputs, out, name=\"KiU-Net\")  # MODEL\n",
        "\n",
        "    return kiunet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWEKHdKoUQQ0"
      },
      "source": [
        "def unet(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Architecture of the U-Net model\n",
        "    :param input_shape: Tuple of the shape of the input\n",
        "    :return: keras.Model\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    print(input_shape)\n",
        "    # ENCODER BLOCK #\n",
        "\n",
        "    s1 = _encoder_block_unet(inputs, 32)  # U NET ENCODER\n",
        "    s2 = _encoder_block_unet(s1, 64)  # UNET ENCODER\n",
        "    s3 = _encoder_block_unet(s2, 128)  # UNET ENCODER\n",
        "    s4 = _encoder_block_unet(s3, 256)  # UNET ENCODER\n",
        "    out = _encoder_block_unet(s4, 512)  # UNET ENCODER\n",
        "\n",
        "    # DECODER BLOCK #\n",
        "\n",
        "    out = _decoder_block_unet(out, 256)\n",
        "    out = layers.Add()([out, s4])\n",
        "    out = _decoder_block_unet(out, 128)\n",
        "    out = layers.Add()([out, s3])\n",
        "    out = _decoder_block_unet(out, 64)  # UNET DECODER\n",
        "    out = layers.Add()([out, s2])  # CONCATENTATION D_U1 & S2 UNET\n",
        "    out = _decoder_block_unet(out, 32)  # UNET DECODER\n",
        "    out = layers.Add()([out, s1])  # CONCATENATION D_U2 & S1 UNET\n",
        "    out = _decoder_block_unet(out, num_classes)  # UNET DECODER\n",
        "    unet_model = tf.keras.Model(inputs, out, name=\"U-Net\")  # MODEL\n",
        "\n",
        "    return unet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrAIvPn6n3Cm"
      },
      "source": [
        "def segnet(input_shape, num_classes):\n",
        "  inputs = layers.Input(shape=input_shape)\n",
        "  s0 = _encoder_block_unet(inputs, 16)\n",
        "  s1 = _encoder_block_unet(s0, 32)\n",
        "  s2 = _encoder_block_unet(s1, 64)  \n",
        "  s3 = _encoder_block_unet(s2, 128)  \n",
        "  s4 = _encoder_block_unet(s3, 256)  \n",
        "  # s4 = _encoder_block_unet(s3, 512)  \n",
        "  # out = _encoder_block_unet(s4, 1024)  \n",
        "\n",
        "  # out = _decoder_block_unet(out, 512)\n",
        "  # out = _decoder_block_unet(out, 256)\n",
        "  out = _decoder_block_unet(s4, 128)\n",
        "  out = _decoder_block_unet(out, 64)\n",
        "  out = _decoder_block_unet(out, 32)\n",
        "  out = _decoder_block_unet(out, 16)\n",
        "  out = _decoder_block_unet(out, num_classes)\n",
        "  segnet_model = tf.keras.Model(inputs, out, name=\"SegNet\")\n",
        "\n",
        "  return segnet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ5yHTc_CfOl"
      },
      "source": [
        "# Import and process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xB7iaKPOrus"
      },
      "source": [
        "x_train = import_data_numpy(\"/content/drive/MyDrive/data/resized/train/img\")\n",
        "y_train = import_data_numpy_mask(\"/content/drive/MyDrive/data/resized/train/labelcol\")\n",
        "x_test = import_data_numpy(\"/content/drive/MyDrive/data/resized/test/img\")\n",
        "y_test = import_data_numpy_mask(\"/content/drive/MyDrive/data/resized/test/labelcol\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3tmTfUElwo0"
      },
      "source": [
        "y_train_binary = np.copy(y_train)\n",
        "y_test_binary = np.copy(y_test)\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  y_train_binary[i][y_train_binary[i] > 0] = 1  \n",
        "  y_test_binary[i][y_test_binary[i] > 0] = 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEIc636areq0"
      },
      "source": [
        "y_onehot_train = keras.utils.to_categorical(y_train_binary, 2)\n",
        "y_onehot_test = keras.utils.to_categorical(y_test_binary, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns31_aoQCh_N"
      },
      "source": [
        "# Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdcv3ugXpLJC"
      },
      "source": [
        "segnet_model = segnet((128,128,3), 2)\n",
        "\n",
        "segnet_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "    metrics=[f1_metric])\n",
        "# Instaniate logging for tensorboard\n",
        "segnet_train_log_dir = \"logs/unet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "segnet_train_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=segnet_train_log_dir, histogram_freq=1)\n",
        "\n",
        "segnet_model.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    \n",
        "                 callbacks=[segnet_train_tensorboard_callback]) \n",
        "segnet_model.save('segnet_model.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFpWoivYvDLY"
      },
      "source": [
        "unet_model = unet((128,128,3), 2)\n",
        "\n",
        "unet_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    \n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  \n",
        "    metrics=[f1_metric])\n",
        "\n",
        "# Instaniate logging for tensorboard\n",
        "unet_train_log_dir = \"logs/unet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "unet_train_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=unet_train_log_dir, histogram_freq=1)\n",
        "\n",
        "unet_model.fit(x_train, y_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_test), verbose=1,   \n",
        "                 callbacks=[unet_train_tensorboard_callback])    \n",
        "\n",
        "unet_model.save('unet_model.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgYl8_lsQLhh"
      },
      "source": [
        "kiunet_model = kiunet((128,128,3), 2)\n",
        "\n",
        "kiunet_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),   \n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  \n",
        "    metrics=[f1_metric])\n",
        "\n",
        "# Instantiate logging for tensorboard\n",
        "kiunet_train_log_dir = \"logs/kiunet/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "kiunet_train_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=kiunet_train_log_dir, histogram_freq=1)\n",
        "\n",
        "\n",
        "kiunet_model.fit(x_train, y_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_test), verbose=1,    \n",
        "                 callbacks=[kiunet_train_tensorboard_callback])\n",
        "\n",
        "kiunet_model.save('kiunet_model.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7XSWHYsCYpc"
      },
      "source": [
        "# 10 KiU-Net models experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IwXhGT_oOUF"
      },
      "source": [
        "kiunet_model_1 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_1.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_1.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_1.save('kiUnet_model_1.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK58aUvxpIA4"
      },
      "source": [
        "kiunet_model_2 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_2.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_2.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_2.save('kiunet_model_2.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJi7azc7pTP4"
      },
      "source": [
        "kiunet_model_3 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_3.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_3.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_3.save('kiunet_model_3.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IU8lpoapank"
      },
      "source": [
        "kiunet_model_4 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_4.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_4.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_4.save('kiunet_model_4.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q5bS6WPpc0R"
      },
      "source": [
        "kiunet_model_5 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_5.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_5.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_5.save('kiunet_model_5.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rWTihSj7phGb"
      },
      "source": [
        "kiunet_model_6 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_6.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_6.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_6.save('kiunet_model_6.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vzmD0fZ4phxX"
      },
      "source": [
        "kiunet_model_7 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_7.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_7.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_7.save('kiunet_model_7.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8d05gH5IpiVb"
      },
      "source": [
        "kiunet_model_8 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_8.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_8.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_8.save('kiunet_model_8.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FJ1glT2bpi0-"
      },
      "source": [
        "kiunet_model_9 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_9.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_9.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_9.save('kiunet_model_9.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcsVavTvpjaU"
      },
      "source": [
        "kiunet_model_10 = kiunet((128,128,3), 2)\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=255)\n",
        "# Save the model structure\n",
        "# kiunet_model.save('kiUnet_structure')\n",
        "\n",
        "kiunet_model_10.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),    ## learning_rate is different from 3D\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),  ##maybe categorical_crossentropy if labels one-hot encoded\n",
        "    metrics=[keras.metrics.MeanIoU(num_classes=255), f1_metric])#check metric, should be 4 classes\n",
        "\n",
        "kiunet_model_10.fit(x_train, y_onehot_train, batch_size=1, epochs=300, \n",
        "                 validation_data=(x_test, y_onehot_test), verbose=1,    ## validation_data = test_data, no early stopping\n",
        "                 callbacks=[kiunet_train_tensorboard_callback])    ## log metrics in TensorBoard\n",
        "\n",
        "\n",
        "## Save again using H5 format\n",
        "kiunet_model_10.save('kiunet_model_10.h5', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glb_y5K3h_Gg"
      },
      "source": [
        "\n",
        "\n",
        "# Evaluate models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6lNujHyB7k5"
      },
      "source": [
        "segnet_model = keras.models.load_model(\"segnet_model.h5\",  custom_objects={'f1_metric': cm.f1_metric})\n",
        "test_pred_segnet = segnet_model.predict(x_test)\n",
        "y_classes_segnet = test_pred_segnet.argmax(axis=-1).flatten()\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "y_onehot = y_onehot_test[:, :, :, 1].flatten()\n",
        "m.update_state(y_classes_segnet, y_onehot)\n",
        "segnet_dice = m.result().numpy()\n",
        "print(\"\\nSeg-Net Evaluation:\")\n",
        "print(\"Dice Score: {}\".format(segnet_dice))\n",
        "segnet_jaccard = f1_score(y_classes_segnet, y_onehot, average=\"macro\")\n",
        "print(\"Jaccard Score: {}\".format(segnet_jaccard))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmzie4ZjCH6y"
      },
      "source": [
        "unet_model = keras.models.load_model(\"unet_model.h5\", custom_objects={'f1_metric': cm.f1_metric})\n",
        "test_pred_unet = unet_model.predict(x_test)\n",
        "y_classes_unet = test_pred_unet.argmax(axis=-1).flatten()\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "y_onehot = y_onehot_test[:, :, :, 1].flatten()\n",
        "m.update_state(y_classes_unet, y_onehot)\n",
        "unet_dice = m.result().numpy()\n",
        "print(\"\\nU-Net Evaluation:\")\n",
        "print(\"Dice Score: {}\".format(unet_dice))\n",
        "unet_jaccard = f1_score(y_classes_unet, y_onehot, average=\"macro\")\n",
        "print(\"Jaccard Score: {}\".format(unet_jaccard))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9AaDLT6CHli"
      },
      "source": [
        "kiunet_model = keras.models.load_model(\"kiUnet_model.h5\", custom_objects={'f1_metric': cm.f1_metric})\n",
        "test_pred_kiunet = kiunet_model.predict(x_test)\n",
        "y_classes_kiunet = test_pred_kiunet.argmax(axis=-1).flatten()\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "y_onehot = y_onehot_test[:, :, :, 1].flatten()\n",
        "m.update_state(y_classes_kiunet, y_onehot)\n",
        "kiunet_dice = m.result().numpy()\n",
        "print(\"\\nKiU-Net Evaluation:\")\n",
        "print(\"Dice Score: {}\".format(kiunet_dice))\n",
        "kiunet_jaccard = f1_score(y_classes_kiunet, y_onehot, average=\"macro\")\n",
        "print(\"Jaccard Score: {}\".format(kiunet_jaccard))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}